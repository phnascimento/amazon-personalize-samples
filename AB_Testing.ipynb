{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMrWw9B0SZy0wzjCSVv24D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phnascimento/amazon-personalize-samples/blob/master/AB_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciHkLR6zf0Cj",
        "outputId": "dec0e6af-2330-4f62-91dd-14f9b4b313f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install -q arviz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.5MB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 16.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 727kB 38.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 49.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQNE_svHf4SN",
        "outputId": "ea1cb1f3-eb67-4435-90c7-e708e1475780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install -q pyspark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 204.2MB 63kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 47.6MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njw3ndG0f7-n",
        "outputId": "68ed4187-6767-4f08-aba8-22b47544f107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "!apt-get update"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Waiting for headers] [Wa\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Waiting for headers] [2 \r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Waiting for headers] [Wa\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rGet:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [39.1 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Ign:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [335 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,681 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,348 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [45.5 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [15.0 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [205 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,112 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,733 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [860 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [231 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,150 kB]\n",
            "Fetched 11.0 MB in 3s (3,796 kB/s)\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dju40JSjf-Uo"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cupMwFZrgCDo",
        "outputId": "6227a7d5-e53a-4443-bc88-a7e87e401513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xB3PlkugOJ4",
        "outputId": "3a9264d4-81a9-490d-d668-07da91c543ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!java -version"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_265\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n_EM78tgPey",
        "outputId": "61bfad9f-14df-4f36-bd20-e45feb5d7a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.getenv(\"JAVA_HOME\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/usr/lib/jvm/java-8-openjdk-amd64'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKrShvV1gSlQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import arviz as az\n",
        "import scipy.stats as stats\n",
        "import pymc3 as pm\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact\n",
        "\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyoFlrg3g03-"
      },
      "source": [
        "sc = SparkSession.builder.appName('LRAC-6330').getOrCreate()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYb4r6xOhgjv"
      },
      "source": [
        "#**LRAC-6330 - Researching ways to parallelize A/B Testing code in Spark**<hr span=30%></hr> \n",
        "\n",
        "**Description**\n",
        "\n",
        "Research the possibility of run the AB Testing code using pymc3 in parallel with Spark. The key to do this is to run multiple Markov chains in parallel to accelerate convergence and to build a more robust model. Other options are to use Tensorflow Probability, but it requrires more fine tuning and low level aspects of the lib and more deep knowledge of the math involved.<br><br>\n",
        "\n",
        "This notebook contains the models descripted in the LRAC-6330 ticket and it's sub-tasks.<br><br><br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##1. Input Data\n",
        "---\n",
        "This is the test data as described in the [repo]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfsz2h-ijX4g",
        "outputId": "ef68dc3e-705c-4f04-f040-f1bc982bfd81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "dataset = pd.DataFrame(data={\n",
        "    'trials':[3025,2895,3200,3523,2065,1645],\n",
        "    'successes':[2235,2132,1789,3002,1245,1135],\n",
        "    'days':[1,2,1,2,1,2]\n",
        "},\n",
        "index=['Control','Control','Variant A','Variant A','Variant B','Variant B']\n",
        ")\n",
        "\n",
        "dataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trials</th>\n",
              "      <th>successes</th>\n",
              "      <th>days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Control</th>\n",
              "      <td>3025</td>\n",
              "      <td>2235</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Control</th>\n",
              "      <td>2895</td>\n",
              "      <td>2132</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant A</th>\n",
              "      <td>3200</td>\n",
              "      <td>1789</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant A</th>\n",
              "      <td>3523</td>\n",
              "      <td>3002</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant B</th>\n",
              "      <td>2065</td>\n",
              "      <td>1245</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant B</th>\n",
              "      <td>1645</td>\n",
              "      <td>1135</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           trials  successes  days\n",
              "Control      3025       2235     1\n",
              "Control      2895       2132     2\n",
              "Variant A    3200       1789     1\n",
              "Variant A    3523       3002     2\n",
              "Variant B    2065       1245     1\n",
              "Variant B    1645       1135     2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZs-BpfGhVfT",
        "outputId": "adf77b37-4576-49df-8abc-506ca1fbb04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "groups = dataset.groupby(dataset.index).agg({'trials':'sum','successes':'sum'})\n",
        "groups"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trials</th>\n",
              "      <th>successes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Control</th>\n",
              "      <td>5920</td>\n",
              "      <td>4367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant A</th>\n",
              "      <td>6723</td>\n",
              "      <td>4791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Variant B</th>\n",
              "      <td>3710</td>\n",
              "      <td>2380</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           trials  successes\n",
              "Control      5920       4367\n",
              "Variant A    6723       4791\n",
              "Variant B    3710       2380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ-YNuZTiBsz",
        "outputId": "e38834c0-8c26-47ba-8797-896e6a1a3e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "probs = groups.assign(rate = lambda df: df['successes']/df['trials'])['rate']\n",
        "probs"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Control      0.737669\n",
              "Variant A    0.712628\n",
              "Variant B    0.641509\n",
              "Name: rate, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZORxR_bDikye"
      },
      "source": [
        "#**LRAC-6564** - Implement Analytical Model for Bayesian A/B Testing in Pyspark\n",
        "---\n",
        "\n",
        "Bayesian A/B Testing for binary count data can be written analytically with only Uniforms, Binomial and Beta distributions. The aim of this ticket is to implement this model to run in a pyspark job to serve as one of the baselines.\n",
        "\n",
        "# A/B testing: binary outcomes<br>\n",
        "For a binary-outcome test (e.g. a test of conversion rates), the probability that B will beat A in the long run is given by:\n",
        "\n",
        "<a href=\"https://www.codecogs.com/eqnedit.php?latex=\\bg_black&space;Pr(\\boldsymbol{p_{B}>p_{A}})&space;=&space;\\boldsymbol{\\sum_{i=0}^{\\alpha_{B-1}}}\\frac{\\boldsymbol{B}(\\alpha_{\\boldsymbol{A}}&space;&plus;&space;i,&space;\\beta_{\\boldsymbol{B}}&space;&plus;&space;\\beta_{\\boldsymbol{A}})}{(\\beta_{\\boldsymbol{B}}&space;&plus;&space;i)\\boldsymbol{B}(1&space;&plus;&space;1,&space;\\beta_{\\boldsymbol{B}})\\boldsymbol{B}(\\alpha_{\\boldsymbol{A}},&space;\\beta_{\\boldsymbol{A}})}\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?\\bg_black&space;Pr(\\boldsymbol{p_{B}>p_{A}})&space;=&space;\\boldsymbol{\\sum_{i=0}^{\\alpha_{B-1}}}\\frac{\\boldsymbol{B}(\\alpha_{\\boldsymbol{A}}&space;&plus;&space;i,&space;\\beta_{\\boldsymbol{B}}&space;&plus;&space;\\beta_{\\boldsymbol{A}})}{(\\beta_{\\boldsymbol{B}}&space;&plus;&space;i)\\boldsymbol{B}(1&space;&plus;&space;1,&space;\\beta_{\\boldsymbol{B}})\\boldsymbol{B}(\\alpha_{\\boldsymbol{A}},&space;\\beta_{\\boldsymbol{A}})}\" title=\"Pr(\\boldsymbol{p_{B}>p_{A}}) = \\boldsymbol{\\sum_{i=0}^{\\alpha_{B-1}}}\\frac{\\boldsymbol{B}(\\alpha_{\\boldsymbol{A}} + i, \\beta_{\\boldsymbol{B}} + \\beta_{\\boldsymbol{A}})}{(\\beta_{\\boldsymbol{B}} + i)\\boldsymbol{B}(1 + 1, \\beta_{\\boldsymbol{B}})\\boldsymbol{B}(\\alpha_{\\boldsymbol{A}}, \\beta_{\\boldsymbol{A}})}\" /></a>\n",
        "\n",
        "Where:\n",
        "\n",
        "$\\alpha_{𝐴}$ is one plus the number of successes for **A**<br>\n",
        "$\\beta_{A}$ is one plus the number of failures for **A**<br>\n",
        "$\\alpha_{B}$ is one plus the number of successes for **B**<br>\n",
        "$\\beta_{B}$ is one plus the number of failures for **B**<br>\n",
        "**𝐵** is the beta function<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5hzQHzakSk7"
      },
      "source": [
        "def run_analytical_model(groups, draws=1000):\n",
        "  \"\"\"\n",
        "  Calculate beta posterior distribution given parameters\n",
        "\n",
        "  This function calculates a beta posterior distribution given a tuple of \n",
        "  successes and trials for each variant (group) in the `groups` parameter \n",
        "  and returns a list of dicts, each one with the name of the variant, \n",
        "  the posterior mean, the median, and the posterior itself with size `draws`.\n",
        "\n",
        "  Parameters\n",
        "  ------------\n",
        "  groups : pandas.DataFrame\n",
        "        DataFrame of Variants, Trials and Successes. Index = 1D variant names\n",
        "        of size 1 to number of unique variants, columns = 1D string array with\n",
        "        values: ['Trials','Successes']\n",
        "  draws:   int\n",
        "        Size or number of data points of the beta posterior\n",
        "        distribution. Default to 1000\n",
        "  Returns\n",
        "  --------\n",
        "  list\n",
        "    List of dicts with data about the posterior distribution of each variant\n",
        "    in the `groups` parameter.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  posterior_traces = []\n",
        "\n",
        "  for name, group in groups.iterrows():\n",
        "    dict_ = dict(name=name, **group)\n",
        "\n",
        "    alpha = dict_.get('successes')\n",
        "    beta = dict_.get('trials')\n",
        "    posterior = stats.beta.rvs(a=alpha+1, \n",
        "                               b=beta-alpha+1, \n",
        "                               size=draws, \n",
        "                               random_state=42)\n",
        "    \n",
        "    posterior_traces.append(dict(\n",
        "            name=name,\n",
        "            expected_value=posterior.mean(),\n",
        "            median=np.median(posterior),\n",
        "            posterior=posterior\n",
        "        ))\n",
        "    \n",
        "  return posterior_traces"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmFlGw-w7CSX"
      },
      "source": [
        "#**LRAC-6566** Implement Hamiltonian Monte Carlo in Pyspark/Tensorflow\n",
        "---\n",
        "\n",
        "Implement the Hamiltonian Monte Carlo sampling algorithm in Tensorflow Probability and run it in a pyspark job"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DihtdSqWqv92"
      },
      "source": [
        "class HamiltonianMonteCarloModel:\n",
        "\n",
        "  def __init__(self, control_group, variant_groups, *, number_of_steps=2000,\n",
        "               burnin=200, leapfrog_steps=3):\n",
        "    self._control_group=control_group\n",
        "    self._variant_groups=variant_groups\n",
        "    self._number_of_steps=number_of_steps\n",
        "    self._burnin=burnin\n",
        "    self._leapfrog_steps=leapfrog_steps\n",
        "    self._list_obs=None\n",
        "    self._list_probs=None\n",
        "    self._observations=None\n",
        "\n",
        "  def set_observed_values(self, list_probs=[.5, .5], list_draws=[1000, 1000]):\n",
        "\n",
        "    observations = []\n",
        "    for i, dist in enumerate(zip(list_probs, list_draws)):\n",
        "      observations.append(\n",
        "          {f'Variant {chr(65 + i)}':stats.bernoulli.rvs(p=dist[0], size=dist[1])}\n",
        "      )\n",
        "    \n",
        "    self._observations=observations\n",
        "\n",
        "    return\n",
        "\n",
        "  def _joint_log_prob(self, observations):\n",
        "\n",
        "    for _ in range(len(observations)):\n",
        "      \n",
        "\n",
        "  def run_hmc_model(self):\n",
        "    initial_chain_state = []\n",
        "    unconstraining_bijectors = []\n",
        "\n",
        "    def joint_log_prob()\n",
        "\n",
        "    for obs in self._observations:\n",
        "\n",
        "\n",
        "\n",
        "# TODO\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZEKibTZmH-t"
      },
      "source": [
        "#**LRAC-6567** - Implement Bayesian Multi-Armed Bandits algorithms in Pyspark/Tensorflow\n",
        "\n",
        "##**Description**\n",
        "\n",
        "Bayesiam Multi-Armed Bandits have been used as an alternative for frequentist and bayesian A/B Testing. The aim of this ticket is to implement this algorithm using Tensorflow Probability to see if it'll be viable to research in the future.<br><br>\n",
        "\n",
        "\n",
        "Unlike standard machine learning tools, bandit algorithms aren't simply black-box functions you can call to process the data you have lying around --- bandit algorithms have to actively select which data you should acquire and analyze that data in real-time. Indeed, bandit algorithms exemplify two types of learning that are not present in standard ML examples: *active learning*, which refers to algorithms that actively select which data they should receive; and *online learning*, which refers to algorithms that analyze data in real-time and provide results on the fly.<br><br>\n",
        "\n",
        "#**Simulating the Arms of a Bandit Problem**\n",
        "\n",
        "In order to reasonably simulate what might happen if we were to deploy an epsilon-Greedy algorithm in production, we need to set up some hypothetical arms. For this, we're going to focus on a very simple type of simulated arm that's easy to implement correctly. This hypothetical arm will let us simulate settings like:<br>\n",
        "\n",
        "* *Optimizing click-throuhg rates for ads:* Every time we show someone an ad, we'll imagine that there's a fixed probability that they'll click on the ad. The bandit algorithm will then estimate this probability and try to decide on a strategy for showing ads that maximizes the click-through rate.\n",
        "* *Conversion rates for new users:* Every time a new visitor comes to our site who isn't already a registered user, we'll imagine that there's a fixed probability that they'll register as a user after seeing the landing page. We'll then estimate this probability and try to decide on a strategy for maximizing our conversion rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F55Dm_rPmwBW"
      },
      "source": [
        "class BernoulliArm:\n",
        "  def __init__(self, p):\n",
        "    self._p=p\n",
        "\n",
        "  def draw(self):\n",
        "    if np.random.random() > self._p:\n",
        "      return 0.0\n",
        "    else:\n",
        "      return 1.0"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fG5rBBot6ae"
      },
      "source": [
        "means = [.1, .1, .5, .9]\n",
        "n_arms = len(means)\n",
        "np.random.shuffle(means)\n",
        "arms = list(map(lambda mu: BernoulliArm(mu), means))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBvnI8GVuLcy",
        "outputId": "71b96ba0-7e4b-4f21-8dfc-e10b523aa2dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[arm.draw() for arm in arms]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 1.0, 1.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaBV_MmnuR26"
      },
      "source": [
        "def test_bandits_algorithm(algo, arms, num_sims, horizon):\n",
        "  \n",
        "  chosen_arms = [0.0 for i in range(num_sims * horizon)]\n",
        "  rewards = [0.0 for i in range(num_sims * horizon)]\n",
        "  cumulative_rewards = [0.0 for i in range(num_sims * horizon)]\n",
        "  sim_nums = [0.0 for i in range(num_sims * horizon)]\n",
        "  times = [0.0 for i in range(num_sims * horizon)]\n",
        "\n",
        "  for sim in range(num_sims):\n",
        "    sim = sim + 1\n",
        "    algo.initialize(len(arms))\n",
        "\n",
        "    for t in range(horizon):\n",
        "      t = t + 1\n",
        "      index = (sim - 1) * horizon + t - 1\n",
        "      sim_nums[index] = sim\n",
        "      times[index] = t\n",
        "\n",
        "      chosen_arm = algo.select_arm()\n",
        "      chosen_arms[index] = chosen_arms\n",
        "      reward = arms[chosen_arms[index]].draw()\n",
        "      rewards[index] = reward\n",
        "\n",
        "      if t == 1:\n",
        "        cumulative_rewards[index] = reward \n",
        "      else:\n",
        "        cumulative_rewards[index] = cumulative_rewards[index - 1] + reward\n",
        "      algo.update(chosen_arm, reward)\n",
        "    \n",
        "    return [sim_nums, times, chosen_arms, rewards, cumulative_rewards]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ByXZzY008c"
      },
      "source": [
        "class EpsilonGreedy:\n",
        "\n",
        "  def __init__(self, )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}